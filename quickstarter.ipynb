{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "TODO: Update the lin\n",
    "<a href=\"https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/endersgame/mean_reversion_attacker/mean_reversion_attacker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cover](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/mid-one/cover.jpg)\n",
    "\n",
    "# En garde, attack!\n",
    "\n",
    "Welcome to Mid+One! Dive into the world of martingales and market dynamics.\n",
    "\n",
    "Your challenge: spot tiny shifts in financial time-series, to predict where prices are heading.\n",
    "\n",
    "It's all about spotting patterns in the elusive mid-price.\n",
    "\n",
    "# The goal\n",
    "\n",
    "## Attacking not forecasting!\n",
    "\n",
    "We don't want to forecast the future prices as this is extremely difficult and requires often a lot of computation. What we want is detect a shift in the market dynamics, up or down, that's it! \n",
    "\n",
    "This is a much simpler task and can be done with a simple model. We also need this decision to be computed quickly! Under 20 milliseconds.\n",
    "\n",
    "To be precise, our attacker will consume a univariate sequence of numerical data points $x_1, x_2, \\dots x_t$ and try to exploit deviations from the [martingale property](https://en.wikipedia.org/wiki/Martingale_(probability_theory)), which is to say that we expect the series $x_t$ to satisfy:\n",
    "$$ E[x_{t+k}] \\approx x_t $$\n",
    "roughly. Of course, there's no such thing in this world as a perfect martingale and it is your job to indicate when\n",
    "$$ E[x_{t+k}] > x_t + \\epsilon $$\n",
    "by returning a positive value, or conversely. Here $\\epsilon$ finds interpretation as a trading cost. The attacker will *typically* return `0` meaning that it thinks:\n",
    "$$  x_t - \\epsilon   > E[x_{t+k}] > x_t + \\epsilon $$\n",
    "because trading opportunities are probably on the rare side - though obviously this is problem dependent. The $\\epsilon$ and $k$ (`horizon`) parameters are set [here](https://github.com/microprediction/midone/blob/main/midone/gameconfig.py).\n",
    "\n",
    "## Scoring\n",
    "\n",
    "The scoring is straightforward: it corresponds to the profit of a simple trading strategy: if the model predicts a move up over some short horizon (corresponding to a few seconds at most), the strategy is to buy now and sell at the end of the horizon minus some transaction costs.\n",
    "\n",
    "If we decided to go up at $t$:\n",
    "$$x_{t+k} - x_t - \\epsilon$$\n",
    "and \n",
    "$$x_t - x_{t+k} - \\epsilon$$\n",
    "if we decided to go down at $t$.\n",
    "\n",
    "The case of a move down is symmetric. In most cases, we don't expect the model to predict a move up or down so we will just do nothing.\n",
    "\n",
    "This is an example of detecting three move ups (the green bands, detecting down would show as red bands), with two resulting in a profit and one with a loss:\n",
    "\n",
    "![Profit](docs/profit.png) \n",
    "\n",
    "# The data\n",
    "\n",
    "This competition is really meant to focus on single streaming series and should be quite agnostic to particular financial instruments. There is a training phase where parameters can be learned on group of similar instruments but overall, we rely on online learning. \n",
    "\n",
    "Let's look right away at some data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Install the crunch CLI\n",
    "- Use the token to get started with data and submission\n",
    "- Setup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:09:26.102038Z",
     "start_time": "2024-10-28T15:09:16.424264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "midplot 0.1.0 requires crunch-cli<5.0.0,>=4.0.3, but you have crunch-cli 5.1.3 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "---\n",
      "Your token seems to have expired or is invalid.\n",
      "\n",
      "Please follow this link to copy and paste your new setup command:\n",
      "https://hub.crunchdao.com/competitions/mid-one/submit\n",
      "\n",
      "If you think that is an error, please contact an administrator.\n",
      "loaded inline runner with module: <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "from nevergrad.benchmark.gymexperiments import ng_gym\n",
    "%pip install --upgrade crunch-cli -q\n",
    "!crunch setup --notebook mid-one cobra --token bff0RrUG5HBNHqQYGVmVCrXvWU4V4Ywgk0qHSYPmV6UvewfDPrmN7Im2FF6JDMtR\n",
    "\n",
    "import crunch\n",
    "crunch = crunch.load_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Timeseries come as streams and you can get many streams, split into `train` and `test` datasets. \n",
    "\n",
    "A stream is sequence of data points represented by a dictionary. The value of the time series is `pt[\"x\"]` where `p` is the point in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:09:33.123255Z",
     "start_time": "2024-10-28T15:09:27.761206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_train.parquet (7049425 bytes)\n",
      "data/X_train.parquet: already exists, file length match\n",
      "data/X_test.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/X_test_reduced.parquet (405611 bytes)\n",
      "data/X_test.parquet: already exists, file length match\n",
      "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_train.parquet (5804278 bytes)\n",
      "data/y_train.parquet: already exists, file length match\n",
      "data/y_test.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/y_test_reduced.parquet (411693 bytes)\n",
      "data/y_test.parquet: already exists, file length match\n",
      "data/example_prediction.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/78/example_prediction_reduced.parquet (59364 bytes)\n",
      "data/example_prediction.parquet: already exists, file length match\n",
      "Loaded 319 training streams and 20 testing streams\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x_train, x_test = crunch.load_streams()\n",
    "\n",
    "print(f\"Loaded {len(x_train)} training streams and {len(x_test)} testing streams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having a peek into the data\n",
    "\n",
    "`midplot` provides a lot of cool features, one is to able to visualize the data.\n",
    "\n",
    "Running over the data sequentially like a live algorithm would do is called `replay`.\n",
    "\n",
    "Let's have a look at the data by replaying the first stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:09:39.746951Z",
     "start_time": "2024-10-28T15:09:35.232896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please define the 'infer' function in the main module: for debugging, showing no attacks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887106ca62ef4c139557c5e8fdf7acf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x10ffe09e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from midplot import replay\n",
    "replay(x_train[:1], with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the comment about the `infer` function not being defined. Crunch will pick up automatically your attack fuction once `infer` is define.\n",
    "\n",
    "We only ran the first stream for space. Alternatively, you can specify certain streams like this:\n",
    "```python\n",
    "replay(x_train, only_stream_ids=[0], with_visualization=True)\n",
    "```\n",
    "\n",
    "To only run a subset of the data, you can also specify a `start` and `stop` index:\n",
    "```python\n",
    "replay(x_train, only_stream_ids=[0], start_index=0, stop_index=1000, with_visualization=True)\n",
    "```\n",
    "\n",
    "### Important flexibility\n",
    "\n",
    "`midplot` let's you pass regular iterable of float as well so you don't have to recreate these small dictionaries so you can easily run your algorithm on your own data -- very useful for debugging.\n",
    "\n",
    "This is how you would attack the `log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T15:10:26.043031Z",
     "start_time": "2024-10-28T15:10:25.959310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please define the 'infer' function in the main module: for debugging, showing no attacks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e511f7b7b83d4813884b1a4770eed6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x138f5cb90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "replay(np.log(range(1, 100)), with_visualization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's attack!\n",
    "\n",
    "Underneath, `crunch` requires an `infer` function. The syntax is not completely trivial so `midplot` provides a helper function to do this.\n",
    "\n",
    "We only need to define an Attacker class like the other notebooks.\n",
    "\n",
    "For demo purposes, we will keep a buffer of points and detect a move if the change of price in the second part of the buffer is higher with a threshoold (and will be adjusted) the move in the first part of the buffer.\n",
    "\n",
    "This is a measure of momentum in some way."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:45.967600Z",
     "start_time": "2024-10-29T17:45:45.959286Z"
    }
   },
   "source": [
    "from midone import HORIZON, EPSILON, Attacker\n",
    "UP, DOWN, NOTHING = 1., -1., 0.\n",
    "\n",
    "\n",
    "class MomentumAttacker(Attacker):\n",
    "    # We will turn this factor into a hyper-parameter!\n",
    "    factor: float = 2.5\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.buffer = []\n",
    "        self.num_points = 100\n",
    "    def tick_and_predict(self, x: float, horizon: int = HORIZON) -> float:\n",
    "        # Add new value and maintain fixed buffer size\n",
    "        self.buffer.append(x)\n",
    "        if len(self.buffer) > self.num_points:\n",
    "            self.buffer.pop(0)  # Remove oldest value\n",
    "\n",
    "        # Wait until we have enough data\n",
    "        if len(self.buffer) < self.num_points:\n",
    "            return NOTHING\n",
    "\n",
    "        # Split buffer into two halves and calculate change in each half\n",
    "        mid = self.num_points // 2\n",
    "        first_half_change = self.buffer[mid - 1] - self.buffer[0]\n",
    "        second_half_change = self.buffer[-1] - self.buffer[mid]\n",
    "        if np.sign(first_half_change) != np.sign(second_half_change):\n",
    "            return NOTHING\n",
    "        # Compare changes to predict trend\n",
    "        if np.abs(second_half_change) > self.factor * np.abs(first_half_change):\n",
    "            return np.sign(second_half_change)\n",
    "        else:\n",
    "            return NOTHING\n",
    "        \n",
    "from midplot.helpers import wrap\n",
    "infer = wrap(MomentumAttacker)"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to\n",
    "```python\n",
    "\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    yield  # We are ready\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        \n",
    "```\n",
    "\n",
    "## Note: what are the `hyper_parameters`, `with_hyper_parameters_load` and `model_directory_path` for?\n",
    "\n",
    "These parameters are important in the training phase where we want to optimize the parameter and save the optimal parameters which we want to load in the inference phase for the actual submission.\n",
    "\n",
    "It would look like this:\n",
    "```python\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    if hyper_parameters is not None:\n",
    "        # Defined on your model\n",
    "        m.update_from_hyper_parameters(hyper_parameters)\n",
    "    if with_hyper_parameters_load:\n",
    "        # Load from the params for final inference\n",
    "        m.load_params(model_directory_path)\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "```\n",
    "\n",
    "and the train function would look something like that:\n",
    "```python\n",
    "\n",
    "def train(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    model_directory_path: str\n",
    "):\n",
    "    hyper_params = {}\n",
    "    def optimize(hyper_params):\n",
    "        res = replay(streams, hyper_parameters=hyper_params)\n",
    "        return - res.total_score\n",
    "    # Your optimization function\n",
    "    hyper_params = optimize(hyper_params)\n",
    "    # Save the parameters\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run the same replay on the first time series\n",
    "\n",
    "The library will automatically call the `infer` function on the data points.\n",
    "\n",
    "Let's also display the scoring for this simple algorithm."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:51.747770Z",
     "start_time": "2024-10-29T17:45:49.228209Z"
    }
   },
   "source": [
    "replay(x_train[:1], stop_index=500, with_accounting_visualizer=True, with_visualization=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        backgroundâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9e3d59098b84eeea4a41757d1926a63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f600cb7b1dea4d11aefaa384dba94d5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x1244ee2d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "\n",
    "On the last replay, you can click on the graph and will select some points of the time series. This let's you select simple case where you would like your algorithm to pick up a move up or down or do nothing.\n",
    "\n",
    "This can be very useful to constraints your training to some behavior. Will do some semi-supervised learning in some way.\n",
    "\n",
    "```python\n",
    "get_replay_result().save_selected(UP)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from midplot import get_replay_result\n",
    "# Run this to save the scenario\n",
    "# get_replay_result().save_selected(UP)"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:51.873936Z",
     "start_time": "2024-10-29T17:45:51.857316Z"
    }
   },
   "source": [
    "from midplot import load_scenarios\n",
    "movie = load_scenarios()\n",
    "print(f\"Loaded {len(movie.scenarios)} scenarios\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 scenarios\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can run all the scenarios like this:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:52.284325Z",
     "start_time": "2024-10-29T17:45:51.991079Z"
    }
   },
   "source": [
    "\n",
    "from midplot.replay import load_scenarios\n",
    "\n",
    "movie = load_scenarios()\n",
    "\n",
    "replay(movie.streams(), horizon=HORIZON, with_accounting_visualizer=True, with_visualization=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        backgroundâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33c747f90bf1480f84d8de8a23db17a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c34c141b267f4ca9b87d0b2ed58c77fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x1240d20c0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even check that the scenarios are successful:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:45:52.337469Z",
     "start_time": "2024-10-29T17:45:52.328119Z"
    }
   },
   "source": [
    "def check_scenarios(threshold=None):\n",
    "    movie = load_scenarios()\n",
    "    r = replay(movie.streams())\n",
    "    return  r.check_scenarios(movie.scenarios, threshold=threshold)\n",
    "\n",
    "ok, checks = check_scenarios(threshold=0.5)\n",
    "print(f\"Failed {len(checks.failed)} Success {len(checks.success)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 1 Success 0\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Let's train!\n",
    "\n",
    "Training here means we will find good values of the parameter of the model, in that case the `factor` parameter.\n",
    "\n",
    "We will use the `nevergrad` package for optimization as an example."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:46:00.409193Z",
     "start_time": "2024-10-29T17:45:52.685968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install nevergrad -q\n",
    "import nevergrad as ng"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:54:29.075621Z",
     "start_time": "2024-10-29T17:54:29.059808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "    \n",
    "def save_param(filename: str, factor: float):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(json.dumps({\"factor\": factor}))\n",
    "            \n",
    "def load_from_param(filename: str) -> MomentumAttacker:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        factor = float(data[\"factor\"])\n",
    "        m = MomentumAttacker()\n",
    "        m.factor = factor\n",
    "        return m\n",
    "            \n",
    "attacker = MomentumAttacker()\n",
    "attacker.factor = 2.7\n",
    "save_param('params.json', attacker.factor)\n",
    "attacker = load_from_param('params.json')\n",
    "assert attacker.factor == 2.7    "
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With this save/load mechanism, we can now build a simple optimizer which we will use for the train function.\n",
    "\n",
    "But first, we need to tweak the `infer` function to load this hyper parameters"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T17:53:26.898588Z",
     "start_time": "2024-10-29T17:53:26.892737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Iterator, Any\n",
    "def infer(\n",
    "        stream: Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = MomentumAttacker()\n",
    "    if hyper_parameters is not None:\n",
    "        m.factor = hyper_parameters \n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick_and_predict(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T18:01:49.235537Z",
     "start_time": "2024-10-29T18:01:49.001106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Iterable\n",
    "import os\n",
    "\n",
    "def train(\n",
    "        streams: List[Iterable[dict]],\n",
    "        model_directory_path: str = \".\"):\n",
    "    factor = ng.p.Scalar(init=1.25, lower=1., upper=3.)\n",
    "    parametrization = ng.p.Instrumentation(factor)\n",
    "    optimizer = ng.optimizers.OnePlusOne(parametrization=parametrization, budget=10)\n",
    "\n",
    "    # Define the objective function that we want to minimize\n",
    "    def objective(factor_value):\n",
    "        # To go faster, only subset of data\n",
    "        r = replay(streams, only_stream_ids=[1, 2], stop_index=500, hyper_parameters=factor_value)\n",
    "        print(f\"Score with factor={factor_value} -> {r.total_score}\")\n",
    "        return - r.total_score\n",
    "\n",
    "    # Run the optimization\n",
    "    recommendation = optimizer.minimize(objective)\n",
    "    # Get the optimal factor value\n",
    "    optimal_factor = recommendation[0].value[0]\n",
    "    print(\"Optimal factor\", optimal_factor)\n",
    "    save_param(os.path.join(model_directory_path, \"params.json\"), optimal_factor)\n",
    "    \n",
    "# We run the optimizer\n",
    "train(x_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.25 -> 32.755076923103516\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.142940912859634 -> 31.510307692339463\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.7836020163489803 -> 27.945923076934697\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.9376434902586688 -> 22.686692307700568\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.4893589527877853 -> 29.23161538464072\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.1128072055025844 -> 33.237076923105334\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.8196837825350471 -> 24.06530769231763\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.1470387219801548 -> 31.510307692339463\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.001050786105901 -> 37.379923076949254\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Loaded with parameter 1.0710946438758828\n",
      "Score with factor=1.878525857688959 -> 20.876000000010922\n",
      "Optimal factor 1.001050786105901\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can finish the proper version of `infer` by adding the loading:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T18:02:11.004329Z",
     "start_time": "2024-10-29T18:02:05.440942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infer(\n",
    "        stream: Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = load_from_param(os.path.join(model_directory_path, \"params.json\")) \n",
    "    print(f\"Loaded with parameter {m.factor}\")\n",
    "    \n",
    "    # This will get ignore\n",
    "    if hyper_parameters is not None:\n",
    "        m.factor = hyper_parameters\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick_and_predict(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        \n",
    "replay(streams=x_train, only_stream_ids=[5], stop_index=1000, with_visualization=True, with_accounting_visualizer=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HTML(value='\\n<style>\\n    .table { \\n        width: 100%; \\n        margin-bottom: 1rem; \\n        backgroundâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "766497ca71854ab2a25c6f0941fc8e1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'lightgrey'},\n",
       "              'mode': 'lines',\n",
       "   â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60a50890c1ac4f45842dbcfbcec992d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded with parameter 1.001050786105901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<midplot.replay.ReplayResults at 0x1245f1820>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### And we are done!"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This is the super charged version with multi-model and the `algos` folder: probably not part of a Quickstart"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:38:41.233935Z",
     "start_time": "2024-10-28T12:38:41.204296Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "import os\n",
    "from algos.diff import Diff\n",
    "\n",
    "from algos.split import Split\n",
    "from algos.momentum import Momentum\n",
    "from algos.optimize import load_params\n",
    "from typing import Any\n",
    "from midplot import replay, get_replay_result\n",
    "from algos.multi import Detector\n",
    "\n",
    "def get_parameter_file_path(model_directory_path: str):\n",
    "    return os.path.join(model_directory_path, 'resources/params.json')\n",
    "\n",
    "\n",
    "\n",
    "def base_model():\n",
    "    return Detector(Momentum, Diff, Split)\n",
    "\n",
    "def infer(\n",
    "        stream: typing.Iterator[dict],\n",
    "        hyper_parameters: Any = None,\n",
    "        with_hyper_parameters_load: bool = False,\n",
    "        model_directory_path: str = \".\",\n",
    "):\n",
    "    m = base_model()\n",
    "\n",
    "    if hyper_parameters is not None:\n",
    "        m.update_models_from_parametrization(hyper_parameters)\n",
    "\n",
    "    if with_hyper_parameters_load:\n",
    "        try:\n",
    "            hyper_parameters = load_params(get_parameter_file_path(model_directory_path))\n",
    "            m.update_models_from_parametrization(hyper_parameters)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    # Signals to the system that your attacker is initialized and ready.\n",
    "    yield  # Leave this here.\n",
    "    for message in stream:\n",
    "        pred = m.tick(message[\"x\"], horizon=HORIZON)\n",
    "        yield pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:38:17.136585Z",
     "start_time": "2024-10-28T12:38:16.824397Z"
    }
   },
   "outputs": [],
   "source": [
    "res = replay(x_train, only_stream_ids=0, stop_index=5000, horizon=HORIZON, epsilon=EPSILON, with_visualization=True, with_accounting_visualizer=True)\n",
    "print(\"Initial\", res.total_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T13:15:32.732994Z",
     "start_time": "2024-10-25T13:15:32.599392Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from algos.optimize import SimpleOptimizer, save_params\n",
    "from midplot.replay import load_scenarios\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def check_scenarios(mov, hyper_parameters, threshold=None):\n",
    "    r = replay(mov.streams(), horizon=HORIZON, epsilon=EPSILON, hyper_parameters=hyper_parameters)\n",
    "    return  r.check_scenarios(mov.scenarios, threshold=threshold)\n",
    "\n",
    "\n",
    "def get_stream_ids():\n",
    "    return random.sample(range(0, len(x_train)), 25)\n",
    "\n",
    "MAX_ITERATIONS = 100\n",
    "\n",
    "def optimize_multi(model_directory_path: str = \".\", budget: int = 5):\n",
    "    m = base_model()\n",
    "    p = m.create_parametrization()\n",
    "    param_file = get_parameter_file_path(model_directory_path)\n",
    "    \n",
    "    optimizer = SimpleOptimizer(p)\n",
    "    \n",
    "    movie = load_scenarios()\n",
    "    print(f\"Loaded {len(movie.scenarios)} scenarios\")\n",
    "    \n",
    "    stream_ids = get_stream_ids()\n",
    "    periods = 0\n",
    "    iteration = 0\n",
    "    num_success_scenarios = None\n",
    "    best_score = - np.inf\n",
    "    \n",
    "    with tqdm(total=budget, desc=\"Optimizing\") as pbar:\n",
    "        while periods < budget:\n",
    "            iteration += 1\n",
    "            if iteration > MAX_ITERATIONS:\n",
    "                break\n",
    "            x = optimizer.ask()\n",
    "            _, p = x\n",
    "            if periods % 10 == 0:\n",
    "                # Check scenarios first\n",
    "                threshold = 0.25 if num_success_scenarios is None else num_success_scenarios / len(movie.scenarios)\n",
    "                ok, scen = check_scenarios(movie, p, threshold=threshold)\n",
    "                if not ok:\n",
    "                    print(f\"Failed at scenarios at {threshold}%: {scen}\")\n",
    "                    optimizer.tell(x, - np.inf)\n",
    "                    if iteration > MAX_ITERATIONS:\n",
    "                        raise Exception(\"Could not find a good solution\")\n",
    "                    continue\n",
    "                print(f\"Success at scenarios at {threshold}%: {scen}\")\n",
    "                num_success_scenarios = len(scen.success)\n",
    "            iteration = 0\n",
    "            periods += 1\n",
    "            r = replay(x_train, horizon=HORIZON, epsilon=EPSILON, only_stream_ids=stream_ids, hyper_parameters=p)\n",
    "            # Print the elapsed time\n",
    "            loss = - r.total_score\n",
    "            if -loss > best_score:\n",
    "                best_score = -loss\n",
    "            # Update the progress bar\n",
    "            print(f\"Period {periods} Score {-loss} Best {best_score}\")\n",
    "            pbar.set_postfix(best_score=best_score)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            optimizer.tell(x, loss)\n",
    "\n",
    "            recommendation = optimizer.recommend()\n",
    "            _, p = recommendation\n",
    "            save_params(p, param_file)\n",
    "\n",
    "    # return recommendation.value\n",
    "\n",
    "print(\"Optimizing\")\n",
    "optimize_multi(\".\", 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6keI5dhzzA91GFxncpHCk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
